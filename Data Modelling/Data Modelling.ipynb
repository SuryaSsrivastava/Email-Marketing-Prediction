{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47b535fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e578feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8545dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>opened</th>\n",
       "      <th>meeting_link_clicked</th>\n",
       "      <th>responded</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>body_length</th>\n",
       "      <th>mean_word_length_subject</th>\n",
       "      <th>mean_word_length_body</th>\n",
       "      <th>mean_sent_length_subject</th>\n",
       "      <th>mean_sent_length_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example1</td>\n",
       "      <td>propel marketing roi advanced analytics</td>\n",
       "      <td>hey recipient name ready see marketing perform...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.114286</td>\n",
       "      <td>39.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example1</td>\n",
       "      <td>data superpower unlock insights us</td>\n",
       "      <td>hi recipient name reaching believe last messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.617647</td>\n",
       "      <td>34.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>example1</td>\n",
       "      <td>turn marketing data decisions let explore</td>\n",
       "      <td>greetings recipient name connected yet convinc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.477273</td>\n",
       "      <td>41.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example1</td>\n",
       "      <td>marketing success click away let chat analytics</td>\n",
       "      <td>hello recipient name clear serious business su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>6.055556</td>\n",
       "      <td>47.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>example1</td>\n",
       "      <td>boost brand visibility proven marketing analyt...</td>\n",
       "      <td>hi recipient name digital age data power espec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>6.414634</td>\n",
       "      <td>60.0</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>HRConsultingSeries</td>\n",
       "      <td>streamline hr boost performance</td>\n",
       "      <td>hello recipient name efficiency king especiall...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.461538</td>\n",
       "      <td>31.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>example1</td>\n",
       "      <td>boost brand visibility</td>\n",
       "      <td>hello recipient name want skyrocket company ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>22.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>example1</td>\n",
       "      <td>outpace competitors insightful analytics</td>\n",
       "      <td>hi recipient name noticed navigating vast univ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>example1</td>\n",
       "      <td>tailored analytics</td>\n",
       "      <td>hey recipient name brand deserves stand custom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.161290</td>\n",
       "      <td>18.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>example1</td>\n",
       "      <td>let make data driven decisions together</td>\n",
       "      <td>dear recipient name help notice potential bran...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>39.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             email_type                                            subject  \\\n",
       "0              example1            propel marketing roi advanced analytics   \n",
       "1              example1                 data superpower unlock insights us   \n",
       "2              example1          turn marketing data decisions let explore   \n",
       "3              example1    marketing success click away let chat analytics   \n",
       "4              example1  boost brand visibility proven marketing analyt...   \n",
       "..                  ...                                                ...   \n",
       "149  HRConsultingSeries                    streamline hr boost performance   \n",
       "150            example1                             boost brand visibility   \n",
       "151            example1           outpace competitors insightful analytics   \n",
       "152            example1                                 tailored analytics   \n",
       "153            example1            let make data driven decisions together   \n",
       "\n",
       "                                                  body  opened  \\\n",
       "0    hey recipient name ready see marketing perform...       0   \n",
       "1    hi recipient name reaching believe last messag...       1   \n",
       "2    greetings recipient name connected yet convinc...       0   \n",
       "3    hello recipient name clear serious business su...       1   \n",
       "4    hi recipient name digital age data power espec...       0   \n",
       "..                                                 ...     ...   \n",
       "149  hello recipient name efficiency king especiall...       1   \n",
       "150  hello recipient name want skyrocket company ma...       1   \n",
       "151  hi recipient name noticed navigating vast univ...       1   \n",
       "152  hey recipient name brand deserves stand custom...       0   \n",
       "153  dear recipient name help notice potential bran...       1   \n",
       "\n",
       "     meeting_link_clicked  responded  subject_length  body_length  \\\n",
       "0                       0          0               5           35   \n",
       "1                       0          0               5           34   \n",
       "2                       0          0               6           44   \n",
       "3                       0          1               7           36   \n",
       "4                       0          0               7           41   \n",
       "..                    ...        ...             ...          ...   \n",
       "149                     0          1               4           26   \n",
       "150                     0          0               3           27   \n",
       "151                     0          0               4           25   \n",
       "152                     0          0               2           31   \n",
       "153                     0          1               6           44   \n",
       "\n",
       "     mean_word_length_subject  mean_word_length_body  \\\n",
       "0                    7.000000               6.114286   \n",
       "1                    6.000000               6.617647   \n",
       "2                    6.000000               6.477273   \n",
       "3                    5.857143               6.055556   \n",
       "4                    7.714286               6.414634   \n",
       "..                        ...                    ...   \n",
       "149                  7.000000               6.461538   \n",
       "150                  6.666667               6.111111   \n",
       "151                  9.250000               5.960000   \n",
       "152                  8.500000               6.161290   \n",
       "153                  5.666667               6.818182   \n",
       "\n",
       "     mean_sent_length_subject  mean_sent_length_body  \n",
       "0                        39.0                  248.0  \n",
       "1                        34.0                  258.0  \n",
       "2                        41.0                  328.0  \n",
       "3                        47.0                  253.0  \n",
       "4                        60.0                  303.0  \n",
       "..                        ...                    ...  \n",
       "149                      31.0                  193.0  \n",
       "150                      22.0                  191.0  \n",
       "151                      40.0                  173.0  \n",
       "152                      18.0                  221.0  \n",
       "153                      39.0                  343.0  \n",
       "\n",
       "[154 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb953972",
   "metadata": {},
   "source": [
    "### Training data for predicting open rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131a406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['email_type','subject','body','subject_length','body_length','mean_word_length_subject','mean_word_length_body','mean_sent_length_subject','mean_sent_length_body','opened']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2127d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a256218b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>body_length</th>\n",
       "      <th>mean_word_length_subject</th>\n",
       "      <th>mean_word_length_body</th>\n",
       "      <th>mean_sent_length_subject</th>\n",
       "      <th>mean_sent_length_body</th>\n",
       "      <th>opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example1</td>\n",
       "      <td>propel marketing roi advanced analytics</td>\n",
       "      <td>hey recipient name ready see marketing perform...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.114286</td>\n",
       "      <td>39.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example1</td>\n",
       "      <td>data superpower unlock insights us</td>\n",
       "      <td>hi recipient name reaching believe last messag...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.617647</td>\n",
       "      <td>34.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>example1</td>\n",
       "      <td>turn marketing data decisions let explore</td>\n",
       "      <td>greetings recipient name connected yet convinc...</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.477273</td>\n",
       "      <td>41.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example1</td>\n",
       "      <td>marketing success click away let chat analytics</td>\n",
       "      <td>hello recipient name clear serious business su...</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>6.055556</td>\n",
       "      <td>47.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>example1</td>\n",
       "      <td>boost brand visibility proven marketing analyt...</td>\n",
       "      <td>hi recipient name digital age data power espec...</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>6.414634</td>\n",
       "      <td>60.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>HRConsultingSeries</td>\n",
       "      <td>streamline hr boost performance</td>\n",
       "      <td>hello recipient name efficiency king especiall...</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.461538</td>\n",
       "      <td>31.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>example1</td>\n",
       "      <td>boost brand visibility</td>\n",
       "      <td>hello recipient name want skyrocket company ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>22.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>example1</td>\n",
       "      <td>outpace competitors insightful analytics</td>\n",
       "      <td>hi recipient name noticed navigating vast univ...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>example1</td>\n",
       "      <td>tailored analytics</td>\n",
       "      <td>hey recipient name brand deserves stand custom...</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.161290</td>\n",
       "      <td>18.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>example1</td>\n",
       "      <td>let make data driven decisions together</td>\n",
       "      <td>dear recipient name help notice potential bran...</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>39.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             email_type                                            subject  \\\n",
       "0              example1            propel marketing roi advanced analytics   \n",
       "1              example1                 data superpower unlock insights us   \n",
       "2              example1          turn marketing data decisions let explore   \n",
       "3              example1    marketing success click away let chat analytics   \n",
       "4              example1  boost brand visibility proven marketing analyt...   \n",
       "..                  ...                                                ...   \n",
       "149  HRConsultingSeries                    streamline hr boost performance   \n",
       "150            example1                             boost brand visibility   \n",
       "151            example1           outpace competitors insightful analytics   \n",
       "152            example1                                 tailored analytics   \n",
       "153            example1            let make data driven decisions together   \n",
       "\n",
       "                                                  body  subject_length  \\\n",
       "0    hey recipient name ready see marketing perform...               5   \n",
       "1    hi recipient name reaching believe last messag...               5   \n",
       "2    greetings recipient name connected yet convinc...               6   \n",
       "3    hello recipient name clear serious business su...               7   \n",
       "4    hi recipient name digital age data power espec...               7   \n",
       "..                                                 ...             ...   \n",
       "149  hello recipient name efficiency king especiall...               4   \n",
       "150  hello recipient name want skyrocket company ma...               3   \n",
       "151  hi recipient name noticed navigating vast univ...               4   \n",
       "152  hey recipient name brand deserves stand custom...               2   \n",
       "153  dear recipient name help notice potential bran...               6   \n",
       "\n",
       "     body_length  mean_word_length_subject  mean_word_length_body  \\\n",
       "0             35                  7.000000               6.114286   \n",
       "1             34                  6.000000               6.617647   \n",
       "2             44                  6.000000               6.477273   \n",
       "3             36                  5.857143               6.055556   \n",
       "4             41                  7.714286               6.414634   \n",
       "..           ...                       ...                    ...   \n",
       "149           26                  7.000000               6.461538   \n",
       "150           27                  6.666667               6.111111   \n",
       "151           25                  9.250000               5.960000   \n",
       "152           31                  8.500000               6.161290   \n",
       "153           44                  5.666667               6.818182   \n",
       "\n",
       "     mean_sent_length_subject  mean_sent_length_body  opened  \n",
       "0                        39.0                  248.0       0  \n",
       "1                        34.0                  258.0       1  \n",
       "2                        41.0                  328.0       0  \n",
       "3                        47.0                  253.0       1  \n",
       "4                        60.0                  303.0       0  \n",
       "..                        ...                    ...     ...  \n",
       "149                      31.0                  193.0       1  \n",
       "150                      22.0                  191.0       1  \n",
       "151                      40.0                  173.0       1  \n",
       "152                      18.0                  221.0       0  \n",
       "153                      39.0                  343.0       1  \n",
       "\n",
       "[154 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ce61a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email_type                  0\n",
       "subject                     0\n",
       "body                        0\n",
       "subject_length              0\n",
       "body_length                 0\n",
       "mean_word_length_subject    0\n",
       "mean_word_length_body       0\n",
       "mean_sent_length_subject    0\n",
       "mean_sent_length_body       0\n",
       "opened                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55450d23",
   "metadata": {},
   "source": [
    "### Split into Train Test and Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "149b46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8f569b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bd8a64a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>body_length</th>\n",
       "      <th>mean_word_length_subject</th>\n",
       "      <th>mean_word_length_body</th>\n",
       "      <th>mean_sent_length_subject</th>\n",
       "      <th>mean_sent_length_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example1</td>\n",
       "      <td>propel marketing roi advanced analytics</td>\n",
       "      <td>hey recipient name ready see marketing perform...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.114286</td>\n",
       "      <td>39.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  email_type                                  subject  \\\n",
       "0   example1  propel marketing roi advanced analytics   \n",
       "\n",
       "                                                body  subject_length  \\\n",
       "0  hey recipient name ready see marketing perform...               5   \n",
       "\n",
       "   body_length  mean_word_length_subject  mean_word_length_body  \\\n",
       "0           35                       7.0               6.114286   \n",
       "\n",
       "   mean_sent_length_subject  mean_sent_length_body  \n",
       "0                      39.0                  248.0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3d6c0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8e3f27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: opened, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e3e9b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 154 len(y): 154 \n",
      "len(X_train): 107, len(X_valid): 31, len(X_test): 16 \n",
      "len(y_train): 107, len(y_valid): 31, len(y_test): 16\n"
     ]
    }
   ],
   "source": [
    "# split the full data 80:20 into training:validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, shuffle = True, random_state=101)\n",
    "\n",
    "# split training data 87.5:12.5 into training:testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, train_size=0.875,shuffle = True,random_state=101)\n",
    "\n",
    "print(\"len(X): {} len(y): {} \\nlen(X_train): {}, len(X_valid): {}, len(X_test): \\\n",
    "{} \\nlen(y_train): {}, len(y_valid): {}, len(y_test): {}\".format(len(X), len(y),\\\n",
    "len(X_train), len(X_valid), len(X_test), len(y_train), len(y_valid), \\\n",
    "len(y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "62b4a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f6b23",
   "metadata": {},
   "source": [
    "### Here We need to convert text to vectors in order to train our model so we'll use following Techniques\n",
    "1. TF - IDF (Term Frequency and Inverse Document Frequency)\n",
    "2. BERT/Transformers with fine tuning (Future Improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a46623",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e4e7f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1596a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup for english language\n",
    "stemmer  = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9553e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create tokenizer\n",
    "def tokenize(text):\n",
    "    return [stemmer.stem(token) for token in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11dd1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'good', 'morn']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tokenize function\n",
    "tokenize(\"Hey Good morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "42618cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "53c2c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "70494efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize,\n",
    "                             stop_words = stop,\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7c06d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'s\", 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=2000, ngram_range=(1, 2),\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                tokenizer=<function tokenize at 0x7fe389135e50>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(pd.concat([X_train.body,X_train.subject],axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "81ac4051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bdb25374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['access', 'achiev', 'acquisit', 'act', 'action', 'action insight',\n",
       "       'action let', 'action market', 'action strategi', 'advanc',\n",
       "       'advanc analyt', 'advanc market', 'advantag', 'advisor',\n",
       "       'advisori', 'ahead', 'alloc', 'alloc market', 'analysi', 'analyt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e48d97",
   "metadata": {},
   "source": [
    "#### Transform Training & validation Data\n",
    "- Transform phrases from training set\n",
    "- Transform phrases from Validation set\n",
    "- Look at some example values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "60d12c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.4 ms, sys: 2.9 ms, total: 81.3 ms\n",
      "Wall time: 82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "body_inputs = vectorizer.transform(X_train.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3d09670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 2000)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "17433b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.4 ms, sys: 2.32 ms, total: 25.8 ms\n",
      "Wall time: 57.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subject_inputs = vectorizer.transform(X_train.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "43c0cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 2000)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "af1396b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 ms, sys: 1.38 ms, total: 27.8 ms\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_inputs_body = vectorizer.transform(X_valid.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "565f06ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 2000)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_inputs_body.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c6e6128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.46 ms, sys: 639 µs, total: 9.1 ms\n",
      "Wall time: 10.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_inputs_subject = vectorizer.transform(X_valid.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8a5bd178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "body_feature_train = pd.DataFrame(body_inputs.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "865f2287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "subject_feature_train = pd.DataFrame(subject_inputs.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "65ce70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "body_feature_validation = pd.DataFrame(validation_inputs_body.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3ab80789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "subject_feature_validation = pd.DataFrame(validation_inputs_subject.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a9b39d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>access</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>action insight</th>\n",
       "      <th>action let</th>\n",
       "      <th>action market</th>\n",
       "      <th>action strategi</th>\n",
       "      <th>advanc</th>\n",
       "      <th>...</th>\n",
       "      <th>would avail</th>\n",
       "      <th>would good</th>\n",
       "      <th>would great</th>\n",
       "      <th>would like</th>\n",
       "      <th>would love</th>\n",
       "      <th>would week</th>\n",
       "      <th>yes</th>\n",
       "      <th>yes meet</th>\n",
       "      <th>yet</th>\n",
       "      <th>yet convinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085007</td>\n",
       "      <td>0.099309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     access  achiev  acquisit  act    action  action insight  action let  \\\n",
       "0       0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "1       0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "2       0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "3       0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "4       0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "..      ...     ...       ...  ...       ...             ...         ...   \n",
       "102     0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "103     0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "104     0.0     0.0  0.127387  0.0  0.085007        0.099309         0.0   \n",
       "105     0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "106     0.0     0.0  0.000000  0.0  0.000000        0.000000         0.0   \n",
       "\n",
       "     action market  action strategi    advanc  ...  would avail  would good  \\\n",
       "0              0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "1              0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "2              0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "3              0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "4              0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "..             ...              ...       ...  ...          ...         ...   \n",
       "102            0.0              0.0  0.000000  ...     0.161829         0.0   \n",
       "103            0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "104            0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "105            0.0              0.0  0.125306  ...     0.000000         0.0   \n",
       "106            0.0              0.0  0.000000  ...     0.000000         0.0   \n",
       "\n",
       "     would great  would like  would love  would week  yes  yes meet       yet  \\\n",
       "0            0.0         0.0    0.124105         0.0  0.0       0.0  0.000000   \n",
       "1            0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "2            0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "3            0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "4            0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "..           ...         ...         ...         ...  ...       ...       ...   \n",
       "102          0.0         0.0    0.000000         0.0  0.0       0.0  0.142072   \n",
       "103          0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "104          0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "105          0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "106          0.0         0.0    0.000000         0.0  0.0       0.0  0.000000   \n",
       "\n",
       "     yet convinc  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "..           ...  \n",
       "102          0.0  \n",
       "103          0.0  \n",
       "104          0.0  \n",
       "105          0.0  \n",
       "106          0.0  \n",
       "\n",
       "[107 rows x 2000 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7dbd9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train.iloc[:,3:].reset_index(drop =True),body_feature_train,subject_feature_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8e414c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.concat([X_valid.iloc[:,3:].reset_index(drop =True),body_feature_validation,subject_feature_validation],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2262380",
   "metadata": {},
   "source": [
    "### Modelling Techniques:\n",
    "Since this is a classification model we'll perform following techniques\n",
    "1. Logistics regression\n",
    "2. Random Forest\n",
    "3. GBDT\n",
    "4. Naive Baiyes\n",
    "5. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef284da",
   "metadata": {},
   "source": [
    "### Model metrics to look\n",
    "1. precision\n",
    "2. recall\n",
    "3. F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cfd3a",
   "metadata": {},
   "source": [
    "#### Model-1 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7bd44740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ed11ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e811fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 177 ms, sys: 4.15 ms, total: 181 ms\n",
      "Wall time: 109 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9d811c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1e8c7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "81ba6e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on training data --> 0.8785046728971962\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on training data -->\",accuracy_score(train_preds,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "02bc6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "27211210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with test(validation) data\n",
    "val_pred_1 = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e3bf6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on validation data--> 0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of prediction on validation data-->\",accuracy_score(y_valid,val_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b434c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on validation data --> 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on validation data -->\",f1_score(y_valid,val_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "da248c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.74      1.00      0.85        23\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.37      0.50      0.43        31\n",
      "weighted avg       0.55      0.74      0.63        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classificatiopn report for model predictions\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_valid,val_pred_1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27859d6",
   "metadata": {},
   "source": [
    "#### Here we are getting 85% f1 score on validation data set that is good to start with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfbb9b",
   "metadata": {},
   "source": [
    "#### lets check the accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b3650967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform small df into vectors\n",
    "test_inputs_body = vectorizer.transform(X_test.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b08f3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform small df into vectors\n",
    "test_inputs_subject = vectorizer.transform(X_test.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f2f73875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "body_feature_test = pd.DataFrame(test_inputs_body.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8017fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamani/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "subject_feature_test = pd.DataFrame(test_inputs_subject.toarray(), columns=vectorizer.get_feature_names()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "864d0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test.iloc[:,3:].reset_index(drop =True),body_feature_test,subject_feature_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "72b41a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "28ed198e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on test data --> 0.5625\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on test data -->\",accuracy_score(test_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f201775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score of prediction on test data--> 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score of prediction on test data-->\",recall_score(test_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d7f024be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on test data --> 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on test data -->\",f1_score(test_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a07ca6",
   "metadata": {},
   "source": [
    "#### We are getting a recall of 61% On newer test data which is not bad to start with we can improve further using LSTM or BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139cb07",
   "metadata": {},
   "source": [
    "#### Model - 2 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "983174fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "83489b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "773b5e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c6392c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_2 = model_2.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "403fe376",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on validation data --> 0.5483870967741935\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on validation data -->\",accuracy_score(train_pred_2,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4208e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score of prediction on validation data--> 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score of prediction on validation data-->\",recall_score(train_pred_2,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4b419368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on validation data --> 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on validation data -->\",f1_score(train_pred_2,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2bdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2a509f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_2 = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "41200c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on test data --> 0.625\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on test data -->\",accuracy_score(test_pred_2,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "97bf15a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score of prediction on test data--> 0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score of prediction on test data-->\",recall_score(test_pred_2,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8d7ca23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on test data --> 0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on test data -->\",f1_score(test_pred_2,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5ffc2",
   "metadata": {},
   "source": [
    "#### Model 3 random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4c449f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "67ece077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5616d74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "17ef30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_3 = model_3.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4ae8a3d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on validation data --> 0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on validation data -->\",accuracy_score(train_pred_3,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1f5ef257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score of prediction on validation data--> 0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score of prediction on validation data-->\",recall_score(train_pred_3,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "db502312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on validation data --> 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on validation data -->\",f1_score(train_pred_3,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343ba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4c3306e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_3 = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "18ad3a77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of prediction on test data --> 0.625\n"
     ]
    }
   ],
   "source": [
    "#accuracy of our prdictions\n",
    "print(\"Accuracy Score of prediction on test data -->\",accuracy_score(test_pred_3,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a4336e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score of prediction on test data--> 0.625\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score of prediction on test data-->\",recall_score(test_pred_3,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "32d891c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on test data --> 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score of prediction on test data -->\",f1_score(test_pred_3,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d582dc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Using Logistic Regression and TF - IDF we are getting f1 score of 69% on test data\n",
    "- Using Decision Trees and TF - IDF we are getting f1 score of 70% on test data\n",
    "- Using Random Forest and TF - IDF we are getting f1 score of **76%** on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4177774",
   "metadata": {},
   "source": [
    "## Imporovements\n",
    "- We can try Fastai with Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT) to feature encode.\n",
    "- We can do Hyperparameter tuning using Optuna which uses bayesian optimization to tune parameters.\n",
    "- Also we can try GBDT and LSTM for better predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
